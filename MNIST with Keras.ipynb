{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayak/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['seed']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_dir = \"/media/sayak/Local Disk/TF Shizzle\"\n",
    "data_dir = \"/media/sayak/Local Disk/TF Shizzle/data\"\n",
    "sub_dir = \"/media/sayak/Local Disk/TF Shizzle/sub\"\n",
    "\n",
    "# check for existence\n",
    "print os.path.exists(root_dir)\n",
    "print os.path.exists(data_dir)\n",
    "print os.path.exists(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'Test.csv'))\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir, 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "#train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "train_x = train_x.reshape(train_x.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir, 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "#test_x = test_x.reshape(-1, 784).astype('float32')\n",
    "test_x = test_x.reshape(test_x.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "#train_x = train_x.astype('float32')\n",
    "#test_x = test_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 1, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape\n",
    "train_x.shape\n",
    "#val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300    3\n",
       "34301    1\n",
       "34302    6\n",
       "34303    8\n",
       "34304    3\n",
       "34305    8\n",
       "34306    8\n",
       "34307    9\n",
       "34308    3\n",
       "34309    8\n",
       "34310    4\n",
       "34311    6\n",
       "34312    6\n",
       "34313    3\n",
       "34314    6\n",
       "34315    7\n",
       "34316    5\n",
       "34317    3\n",
       "34318    0\n",
       "34319    3\n",
       "34320    9\n",
       "34321    3\n",
       "34322    8\n",
       "34323    8\n",
       "34324    7\n",
       "34325    4\n",
       "34326    3\n",
       "34327    8\n",
       "34328    6\n",
       "34329    5\n",
       "        ..\n",
       "48970    7\n",
       "48971    5\n",
       "48972    0\n",
       "48973    1\n",
       "48974    4\n",
       "48975    1\n",
       "48976    7\n",
       "48977    5\n",
       "48978    6\n",
       "48979    5\n",
       "48980    6\n",
       "48981    3\n",
       "48982    5\n",
       "48983    5\n",
       "48984    9\n",
       "48985    2\n",
       "48986    9\n",
       "48987    0\n",
       "48988    0\n",
       "48989    7\n",
       "48990    0\n",
       "48991    1\n",
       "48992    1\n",
       "48993    6\n",
       "48994    9\n",
       "48995    2\n",
       "48996    4\n",
       "48997    9\n",
       "48998    3\n",
       "48999    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.ix[split_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 1, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "49000/49000 [==============================] - 212s - loss: 0.3611 - acc: 0.8868 - val_loss: 0.0987 - val_acc: 0.9701\n",
      "Epoch 2/5\n",
      "49000/49000 [==============================] - 205s - loss: 0.0967 - acc: 0.9696 - val_loss: 0.0546 - val_acc: 0.9838\n",
      "Epoch 3/5\n",
      "49000/49000 [==============================] - 206s - loss: 0.0688 - acc: 0.9785 - val_loss: 0.0469 - val_acc: 0.9854\n",
      "Epoch 4/5\n",
      "49000/49000 [==============================] - 211s - loss: 0.0550 - acc: 0.9826 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "Epoch 5/5\n",
      "49000/49000 [==============================] - 226s - loss: 0.0462 - acc: 0.9853 - val_loss: 0.0281 - val_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_x = train_x.reshape(train_x.shape[0], img_cols, img_rows, 1)\n",
    "#test_x = test_x.reshape(test_x.shape[0], img_cols, img_rows, 1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "#input_num_units = 784\n",
    "#hidden_num_units = 50\n",
    "#output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20992/21000 [============================>.] - ETA: 0sPrediction is:  0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join(data_dir, 'Images', 'test', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print \"Prediction is: \", pred[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))\n",
    "\n",
    "sample_submission.filename = test.filename\n",
    "\n",
    "sample_submission.label = pred\n",
    "\n",
    "sample_submission.to_csv(os.path.join(sub_dir, 'sub01.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
